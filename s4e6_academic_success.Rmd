---
title: "s4e6_academic_success_classification"
author: "WangYong"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## The goal 
- predict academic risk of students in higher education.

- evaluation metric: accuracy
0.48108 with sample_submission.csv
0.81783 with glmnet and recipe baseline

- machine learning workflow: R tidymodel workflow/workflows



## librar y & load_data

### library

```{r}
library(tidyverse)
library(tidymodels)
# Explicitly resolve conflicts
tidymodels_prefer()
library(finetune)
library(future)
library(purrr)
library(furrr)
library(textrecipes)
library(themis)


library(bonsai)
library(lightgbm)
library(xgboost)
library(ranger)

library(readr)
library(janitor)
library(lubridate)

library(text2vec)

```

### loading data

```{r}
data_path <- '../input/playground-series-s4e6/'
train<- 
  readr::read_csv(file.path(data_path, 'train.csv'),
                  show_col_types = FALSE)|>
  janitor::clean_names()|>
  mutate(target=as.factor(target))
test <- 
  readr::read_csv(file.path(data_path, 'test.csv'),
                  show_col_types = FALSE)|>
   janitor::clean_names()
submission <-  readr::read_csv(file.path(data_path, 'sample_submission.csv'),show_col_types = FALSE)
```

### quick skim

```{r cache = TRUE}
my_skim <- skimr::skim_with(numeric = skimr::sfl( p25 = NULL, p75 = NULL))
train|> my_skim()
```

```{r cache=TRUE}
test|> skimr::skim()
```

```{r cache=TRUE}
submission |> skimr::skim()
```

### check if train & test is same distribution

```{r}
get_df_var<-function(df){
  df|>
    select(-any_of(c('id','target')))|>
    summarize_all(var)|>
    pivot_longer(cols=everything(),
                 names_to='feature',
                 values_to='variance')

}
list(train=train, test=test)|>
  map_dfr(\(x) get_df_var(x), .id = "dataset") |>
  pivot_wider(names_from=dataset, values_from = variance)|>
  mutate(pct_change=(train-test)/train)#|>arrange(desc(abs(diff)))
```

### Finding of different distribution
- education special need -0.106%
- international 0.126%
- curricular_unit_2nd_sem_credited 0.11%


## EDA

## Models
### data resample
```{r}
set.seed(1234)
df_split <- initial_split(train, prop = 0.8,strata = target)
train_set <- training(df_split)
test_set <- testing(df_split)
cv_folds <- vfold_cv(train_set,
                     v = 3, 
                     repeats = 1,
                     strata = target)
```

### recipies
#### v0
```{r}
rcp_v0 <- 
  recipe(target ~ ., data = train_set) |>
  update_role(id, new_role = 'ID') #|>
  #step_impute_median(all_numeric_predictors()) |>
  #step_normalize(all_numeric_predictors())
```
#### v1_baseline
```{r}
rcp_v1_bs <- 
  recipe(target ~ ., data = train_set) |>
  update_role(id, new_role = 'ID') |>
  step_impute_median(all_numeric_predictors()) |>
  step_normalize(all_numeric_predictors())
```

#### v2_factor
```{r}
rcp_v2_fc <- 
  recipe(target ~ ., data = train_set) |>
  update_role(id, new_role = 'ID') |>
  step_impute_median(all_numeric_predictors()) |>
  step_mutate_at(c('marital_status','application_mode','application_order','course'),
                 fn=as_factor)|>
  step_novel(all_nominal_predictors())|>
  step_unknown(all_nominal_predictors())|>
  step_other(all_nominal_predictors())|>
  step_dummy(all_nominal_predictors() )|>
  #step_zv(all_numeric_predictors())|>
  #step_corr(all_numeric_predictors())|>
  step_normalize(all_numeric_predictors())

rcp_v2_fc |>prep()|>juice()|>glimpse()
```


### engines
```{r}
glm_eng <- 
  multinom_reg(penalty = 0.01623777,
               mixture = 0.05) |>  # Example penalty and mixture values
  set_engine('nnet') |>
  set_mode("classification")    # Specify classification

lgbm_eng<-
   parsnip::boost_tree(
      trees = 500, # Number of trees
      learn_rate = 0.01,
      tree_depth =5,
      loss_reduction = 0.001,
      stop_iter = 50,
      sample_size = 0.9, # Added sample_size
      #tree_depth = tune(),
      #mtry = 0.5,
      min_n = 100
   ) |>
   set_mode("classification")|>
   set_engine("lightgbm",
              #metric='roc_auc', 
              num_leaves = 20,
              counts = FALSE,
              num_threads=12,
              metric = "auc",              # 优化目标
              # reg_alpha=0.01,
              # reg_lambda = 0.5,
              verbose=1) 

rf_eng<- rand_forest( trees = 700, 
                      #mtry=100, 
                      min_n=100) |>
  set_engine("ranger",num.threads=4)|>
  set_mode("classification") 

xgb_eng<- parsnip::boost_tree( trees = 500, 
                      learn_rate = 0.01,
                      loss_reduction = 0.001,
                      sample_size = 0.8, # Added sample_size
                      #mtry=tune(),
                      min_n=70) |>
  set_engine("xgboost",num.threads=8)|>
  set_mode("classification")
#[1] "use_C5.0"             "use_cubist"           "use_earth"            "use_glmnet"           "use_kernlab_svm_poly" "use_kernlab_svm_rbf" 
#[7] "use_kknn"             "use_ranger"           "use_xgboost" 

c50_eng <- boost_tree() |>
  set_mode('classification')|>
  set_engine('C5.0')

earth_eng <-  # good model base score 0.8718
  mars() %>% 
  set_mode("classification") %>% 
  set_engine("earth") 

svm_eng <- 
  svm_rbf(
    cost = 0.001, 
    rbf_sigma = 0.01
    ) %>% 
  set_mode("classification") 

kknn_eng <- 
  nearest_neighbor(neighbors = 5, 
                   #weight_func = tune()
                   ) %>% 
  set_mode("classification") %>% 
  set_engine("kknn") 

selected_eng <- list(glm=glm_eng,
                     rf=rf_eng,
                     lgbm=lgbm_eng,
                     xgb=xgb_eng,
                     #c50=c50_eng,
                     earth= earth_eng,
                     #kknn=kknn_eng,
                     svm=svm_eng
                     
                     )


```

#### set metrics
```{r}
acu_metrics <- metric_set(accuracy,precision) # main goal is roc_auc, accuracy is just for reference
```

### workflow

#### simple start

```{r}
set.seed(1234)

simple_wf_fit<- 
  workflow() |>
  add_recipe(rcp_v2_fc) |>
  add_model(glm_eng)|>
  last_fit(df_split)

# simple_wf_result <-
#   simple_wf_fit|>
#   fit_resamples(cv_folds,
#   #  last_fit(df_split,
#           control = control_resamples(verbose=TRUE),
#            metrics=acu_metrics)
# #plan(sequential)
 simple_wf_fit |> collect_metrics()
#   extract_fit_engine()|>
#   plot()
#simple_wf_fit < -simple_wf_fit |> last_fit(df_split) 
```

#### workflowset with multiple reciepes

### Tune hyperparameters

### Stack


```{r}
set.seed(1234)
library(future)
#plan(multisession,workers = 4)
combined_fit <-
  stacks::stacks()|>
  stacks::add_candidates(wfs_result)|>
  stacks::blend_predictions(penalty = 10^seq(-2, -0.1, length = 20))|>
  stacks::fit_members()

combined_fit|>
  autoplot(type = "weights")

autoplot(combined_fit)
#plan(sequential)
```

## Evaluation on Test 

```{r}
final_model <- 
  #combined_fit # stack case - complex 
  simple_wf_fit|>extract_workflow() # simple workflow

combined_test_result <- 
  test_set %>%
  bind_cols(predict(final_model, 
                    new_data=test_set,type='class'))
combined_test_result|>acu_metrics(truth=target, estimate=.pred_class)
```


### Predic & Sumbit

```{r}
set.seed(1234)
library(future)
plan(multisession,workers = 4)

#final_model <- simple_wf_fit|>extract_workflow()
final_predictions <- final_model |>
   predict(new_data = test,type='class')
plan(sequential)

 # #Handle negative predictions
 # final_predictions <- final_predictions |>
 #   mutate(.pred= ifelse(.pred< 0, 0, .pred))

 # Save submission file
 submission |>
   mutate(Target=final_predictions$.pred_class)|>
   readr::write_csv("submission.csv")
 zip('submission.csv.zip','submission.csv')
```

## Submit to kaggle
```{r}
# submit latest submission.csv
system('kaggle competitions submit -c playground-series-s4e6 -f submission.csv.zip -m "inital"')

Sys.sleep(15)
# get latest score 
system('kaggle competitions submissions -q -c playground-series-s4e6')
# 
# # get leader board score
# #system('kaggle competitions leaderboard -s -v -c playground-series-s4e8')
```

### notebook convert
```{r}
 library(rmd2jupyter)
 rmd2jupyter('s4e6_academic_success.Rmd')
```
